---
title: "Intro to Exploratory Data Analysis in R"
output: html_notebook
---

# Introduction 

Exploratory data analysis (EDA) has been described as "the art of looking at data in a careful and structured way" and seeks to  "use visualisation and transformation to explore your data in a systematic way." These techniques are typically applied before formal modeling commences and can help inform the development of more complex statistical models.

As stated in [R for Data Science](https://r4ds.had.co.nz/exploratory-data-analysis.html) 

> EDA is not a formal process with a strict set of rules. More than anything, EDA is a state of mind. During the initial phases of EDA you should feel free to investigate every idea that occurs to you. Some of these ideas will pan out, and some will be dead ends. As your exploration continues, you will home in on a few particularly productive areas that you’ll eventually write up and communicate to others.

Many books on data science include a chapter(s) on EDA and there are even a few books entirely dedicated to EDA ([Exploratory Data Analysis with R](https://bookdown.org/rdpeng/exdata/) is freely available online). The point is that EDA is an extremely important part of any dat aanalyses. 


In order to get things starter, we describe, following the book Exploratory Data Analysis Using R, a  general strategy for conducting an EDA:

1) Assess the general characteristics of the dataset, *e.g.*:

    a) How many observations do we have? How many variables?
    b) What are the variable names? Are they meaningful?
    c) What type is each variable—e.g., numeric, categorical, logical?
    d) How many unique values does each variable have?
    e) What value occurs most frequently, and how often does it occur?
    f) Are there missing observations? If so, how frequently does this occur?
  
2) Examine descriptive statistics for each variable;

3) Where possible—certainly for any variable of particular interest—examine exploratory visualizations;

4) Look for data anomalies;

5) Look at the relations between key variables;

6) Finally, summarize results of EDA to serve as a basis for subsequent analysis and explanation of the results.

**Important** Reproducibility is very important in EDA. If someone can not follow your steps or if  you can not retrace your steps then EDA has lost much of its power and usefulness. 

# Initial Steps

To begin an EDA in R, you need to load your data into R. It is also recommended that you load any libraries or packages that you will use. When conducting an EDA it is highly advisable to work in a notebook environment in order to optimize reproducibility and to help in communicating your results to others. 

## Load essential packages

As we have mentioned before, the tidyvrese family of packages contain functions that facilitate EDA. Thus, we will begin the process by loading the tidyverse package.  
```{r,warning=FALSE,message=FALSE}
library(tidyverse)
```

## Import data

Here we will work with a running example. Here we will explore data related to a fivethirtyeight article on the [the economics of college majors](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/). 

**Homework** Read this article. In the near future we will have an in-class exercise related to this article. As you read the article, consider the following points:

1) Can all of the claims made in the article be derived from the provided data sets?

2) Can all of the claims made in the article be justified with the provided data sets?

3) Is it clear or not what exactly is in the data? 

4) Does the article make appropriate use of the data? 

5) Can you discover anything from the dat abeyond what is presented in the article? 

Load the data from [here](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/):
```{r,message=FALSE}
grads_df <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/college-majors/recent-grads.csv")
```


## Determine basic data characteristics

Let's look at the size of our data:
```{r}
dim(grads_df)
```
Thus there are 173 rows (observations) and 21 columns (variables). 

Let's examine the head and tail of our data:
```{r}
head(grads_df)
```


```{r}
tail(grads_df)
```

**Exercise:** Look at the source of the data, [here](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/), specifically the recent-grads csv file. Did the data load properly?

**Exercise** What does each column in the data frame represent? Are the column names meaningful? 

Recall that you can list all column names with
```{r}
names(grads_df)
```

**Question:** What is the meaning of college jobs, noncollege jobs, and low wage jobs? 


**Question:** How many variables are numeric? How many variables are categorical? Are there any other structural features to the variables? 

We can easily determine the number of uniqie elements of a particular variable with
```{r}
length(unique(grads_df$Major_category))
```
 
We can simultaneously apply this to each column of the data with
```{r}
apply(grads_df,2,function(x) length(unique(x)))
```

**Question** What can you determine from this result? 

Let's call the summary function:
```{r}
summary(grads_df)
```

The data seems to already be in pretty good shape. We probably don't need to spend any time initially cleaning the data although later we might want to do some data wrangling to explore patterns that are not obvious from the start. 
  
Notice that there are some missing values. It's important to asses whether the missing values are contained all in a single row or if they might be spread out across the data. Here is one way to do this:
```{r}
sum(complete.cases(grads_df))
```
Therefore we see that all of the missing values are in a single row. 

**Question** Why do we draw this conclusion and how does it work? 

We can determine which row contains the missing values with
```{r}
grads_df[!complete.cases(grads_df) , ]
```

It is row 22. One question we might need to ask is why is the data missing for this observation. It may not be important here but in many applications a determination of why data is missing is relevant.  

**Question:** What types of questions might we be able to use this data to ask and/or answer? 

## Variable distributions

Let's look at the distribution of our variables. This is pointless to do for Rank, Major_code, and Major, why? 

Major_category is a categorical variable (factor) that we can visualize easily with a bar plot:
```{r}
grads_df %>% ggplot() + geom_bar(aes(x=Major_category)) + coord_flip()
```

**Question:** What do we learn form this plot? What questions does this plot inspire? 

Next, let's look at the Total variable which is numeric so a histogram might be appropriate:
```{r}
grads_df %>% ggplot() + geom_histogram(aes(x=Total))
```

**Question:** What do we learn from this plot? What questions does this plot inspire?

One idea that is often useful (maybe even necessary) is to rescale (or transform) the variable. For example, rather than plotting the exact values for the Total variable, maybe it makes sense to plot the $\log_{10}$ of the Total values. This is easily achieved as
```{r}
grads_df %>% ggplot() + geom_histogram(aes(x=log10(Total)))
```
 
**Question:** Why do we observe the difference that we do when comparing the last two plots? 

A boxplot may also be helpful here:
```{r}
grads_df %>% ggplot() + geom_boxplot(aes(y=Total))
```

There appears to be a good number of outliers in the Total variable. What is the source of or explanation for these outliers? 

Observe the result of the following calculation:
```{r}
log10(median(grads_df$Total,na.rm = T))
```

A more complete picture of Total may be obtained showing the breakdown of Total by Men and Women, and major category:
```{r}
grads_df %>% gather(Men,Women,key="Gender",value="Number") %>% ggplot() + geom_freqpoly(aes(x=log10(Number),color=Gender)) + 
  facet_wrap(~Major_category)
```


**Question:** What does this graph demonstrate about the data? 


Suppose that we want to know how many majors produce graduates with more than fifty percent being women. We can add on a binary variable with 1 if Sharewomen is more than 0.5 an 0 otherwise:
```{r}
grads_df <- grads_df %>% mutate(greaterHalfWomen=ifelse(ShareWomen > 0.5,1,0))
```

Let's check the result:

```{r}
head(grads_df)
```

Let's use this to count the numbers of majors with more than fifty percent women:
```{r}
sum(grads_df$greaterHalfWomen,na.rm = T)
```

Let's do this is aggregate by major cateogry and include the number of majors that are in each major category:
```{r}
grads_df %>% group_by(Major_category) %>% summarise(ghw=sum(greaterHalfWomen,na.rm = T),in_category=n())
```

**Question** What do you observe from this information? 

Now let's look at the Median variable which reports the median earnings of graduates from each of the represented majors. 

We start with a histogram and boxplot as usual:
```{r}
grads_df %>% ggplot() + geom_histogram(aes(x=Median))
```


```{r}
grads_df %>% ggplot() + geom_boxplot(aes(y=Median))
```

**Question:** What do you observe from these last two plots?  

It is probably a good idea look at median earning across the major categories. One way to do this is 
```{r}
grads_df %>% ggplot() + geom_boxplot(aes(x=Major_category,y=Median)) + coord_flip()
```

Just for purposes of comparison, let's add an line that indicates the average of the median earnings across majors:
```{r}
grads_df %>% ggplot() + geom_boxplot(aes(x=Major_category,y=Median)) + 
  geom_hline(yintercept=mean(grads_df$Median),color="blue") +
  coord_flip()
```

Let's also compute the median and mean of the median earnings aggregated by major category:
```{r}
grads_df %>% group_by(Major_category) %>% summarise(mean_me=mean(Median),median_me=median(Median))
```

**Question:** What is your take away from the aggegate summary and previous plot? 

Of course, only looking at the median can be misleading (why?) so let's examine the 25th and 75th percentiles (which are both inlcuded in the data) as well as the median. We will plot all three together as a function of the rank:
```{r}
grads_df %>% gather(Median,P25th,P75th,key="quantile",value="earning") %>% 
  ggplot(aes(x=Rank,y=earning,color=quantile)) + geom_point()
```

**Question:** What is your take away from the last plot? 

Complementing this with "smoothing lines" might help to bring out the pattern. 
```{r}
grads_df %>% gather(Median,P25th,P75th,key="quantile",value="earning") %>% 
  ggplot(aes(x=Rank,y=earning,color=quantile)) + geom_point() + geom_smooth()
```

**Exercise:**  Explore the ShareWomen variable. What do you observe? 

We should examine the distributions for all of the variables in the data. In consideration of time let's just look at one more, the unemployment rate. 

Here is a histogram and boxplot for unemployment:
```{r}
grads_df %>% ggplot() + geom_histogram(aes(x=Unemployment_rate))
```

```{r}
grads_df %>% ggplot() + geom_boxplot(aes(y=Unemployment_rate))
```

**Question:** What can you determine from the last two plots? 


Let's look at the distributions of unemployment rate across major categories:
```{r}
grads_df %>% ggplot() + geom_freqpoly(aes(x=Unemployment_rate,color=Major_category))
```

```{r}
grads_df %>% ggplot() + geom_boxplot(aes(x=Major_category,y=Unemployment_rate)) + 
  coord_flip()
```

**Question:** What information can be gleaned from the last two plots? Is there any other additional aspects that can be considered with regard to unemployment? 

Note that one topic that we can not easily consider directly using this data is the relationship between gender and employment and income since the employment and salary related data are not broken down by Women/Men. 

## Relations between key variables

**Question** What are the key variables that we should explore the relationships between?

Let's begin by looking at Unemployed versus Total:
```{r}
grads_df %>% ggplot() + geom_point(aes(x=Total,y=Unemployed))
```

**Question:** What observations do you make based on this plot? 

Let's add in the extra dimension of Major_category:
```{r}
grads_df %>% ggplot() + geom_point(aes(x=Total,y=Unemployed,color=Major_category))
```

**Question:** Do you think it makes sense for large values for Unemployed to correspond to large values for Total? 

We may also want to consider the relation between the percent of women in a major and the unemployment rate. 

```{r}
grads_df %>% ggplot() + geom_point(aes(x=ShareWomen,y=Unemployment_rate))
```

**Question:** What do you observe from this plot? 

Let's add the extra dimension of major category:
```{r}
grads_df %>% ggplot() + geom_point(aes(x=ShareWomen,y=Unemployment_rate,color=Major_category))
```

or perhaps even 

```{r}
grads_df %>% ggplot() + 
  geom_point(aes(x=ShareWomen,y=Unemployment_rate,color=Major_category)) + 
  facet_wrap(~Major_category)
```

There are a variety of ways that we can explore relationships between variables in a data set and you are encouraged to go beyond what we do in this notebook. Let's warp up our intro to EDA with one further task. If you look at the the site for the data resource [here](), you will see that there are actually five different data sets. Three of then are already incorporated into the data set  we have already been exploring. But there is one that contains information that is not in our current data set. Let's combine the two together by matching with a column that they both have in common. 

First we read in the additional data set:
```{r}
students_df <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/college-majors/grad-students.csv")
```

These two data sets have the Major_code (and Major) in common, let's confirm this:

```{r}
grads_df %>% arrange(Major_code) %>%  head()
```

```{r}
students_df %>% arrange(Major_code) %>%  head()
```

```{r}
grads_df %>% arrange(Major_code) %>%  tail()
```


```{r}
students_df %>% arrange(Major_code) %>%  tail()
```

```{r}
names(grads_df)
```

```{r}
names(students_df)
```

Notice that these two have more than one column in commmon. Let's remove the redundancy and then merge:
```{r}
students_df <- students_df %>% select(-Major,-Major_category)
```


```{r}
merged_df <- merge(grads_df,students_df,by="Major_code")
```

Now let's examine the result:
```{r}
names(merged_df)
```

```{r}
head(merged_df)
```

Moving forward we will see some additional EDA techniques and results. 

**Exercise:** Conduct additional explorations of the data from our running example that we have not done already. 









